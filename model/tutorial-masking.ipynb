{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "### padding mask\n",
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise.\n",
    "\n",
    "mask 序列中的 pad tokens. 保证模型不会把 pad token 当做输入。mask indicates 在 pad 的位置输出 1，其他位置输出 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    \n",
    "    # add extra dimensions so that we can add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # [batch_size, 1, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里增加两个 newaxis  主要是为了后面的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33, shape=(5,), dtype=float32, numpy=array([0., 0., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)[0,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look-ahead mask\n",
    "\n",
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on.\n",
    "\n",
    "在 decoder 时，预测下一个词的时候需要 mask 序列中之后的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask   # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.19278264 0.38801312 0.7854575 ]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=65, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.linalg.band_part\n",
    "```python\n",
    "tf.linalg.band_part(\n",
    "    input,\n",
    "    num_lower,\n",
    "    num_upper,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "\n",
    "band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]\n",
    "\n",
    "in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) && (num_upper < 0 || (n-m) <= num_upper).\n",
    "```\n",
    "\n",
    "input:要输入的张量tensor.\n",
    "\n",
    "num_lower:下三角矩阵保留的副对角线数量，从主对角线开始计算，相当于下三角的带宽。取值为负数时，则全部保留，矩阵不变。\n",
    "\n",
    "num_upper:上三角矩阵保留的副对角线数量，从主对角线开始计算，相当于上三角的带宽。取值为负数时，则全部保留，矩阵不变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = tf.constant([[ 0,  1,  2, 3],\n",
    "                       [-1,  0,  1, 2],\n",
    "                       [-2, -1,  0, 1],\n",
    "                       [-3, -2, -1, 0]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=80, shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [-1.,  0.,  1.,  2.],\n",
       "       [ 0., -1.,  0.,  1.],\n",
       "       [ 0.,  0., -1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(input_a, 1, -1)  # 下三角保留一个带宽，上三角全部保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84, shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  0.,  0.],\n",
       "       [-1.,  0.,  1.,  0.],\n",
       "       [-2., -1.,  0.,  1.],\n",
       "       [ 0., -2., -1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(input_a, 2, 1)  # 下三角保留2个带宽，上三角保留 1 个带宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-tf2",
   "language": "python",
   "name": "py3-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
